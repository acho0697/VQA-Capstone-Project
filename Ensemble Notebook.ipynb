{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from statistics import mean, stdev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(List): \n",
    "    return max(set(List), key = List.count)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ensemble_results(experiment_prefix, num_of_models, path):\n",
    "    \n",
    "    output = {}\n",
    "    \n",
    "    files = []\n",
    "    for num in range(1,num_of_models+1):\n",
    "        files.append(experiment_prefix+str(num))\n",
    "    \n",
    "    \n",
    "    val_predictions_all = []\n",
    "    results_files = []\n",
    "\n",
    "    for file in files:\n",
    "        with open(path + 'preds/{}/valPredictions-{}.json'.format(file,file), 'r') as f:\n",
    "            val_predictions_all.append(json.load(f))\n",
    "            \n",
    "        with open(path + 'results/{}/results-{}.csv'.format(file,file), 'r') as f:\n",
    "            results_files.append(pd.read_csv(f, header=1))\n",
    "            \n",
    "            \n",
    "\n",
    "    num_of_preds = len(val_predictions_all[0])\n",
    "\n",
    "    accuracies = []\n",
    "\n",
    "    for pred in range(num_of_preds):\n",
    "        answer = val_predictions_all[0][pred]['answer']\n",
    "        predictions = []\n",
    "        for index, file in enumerate(files):\n",
    "            predictions.append(val_predictions_all[index][pred]['prediction'])\n",
    "        if answer == most_frequent(predictions):\n",
    "            accuracies.append(1.0)\n",
    "        else:\n",
    "            accuracies.append(0.0)  \n",
    "            \n",
    "            \n",
    "            \n",
    "    output['ensemble_accuracy'] = mean(accuracies)\n",
    "    \n",
    "    \n",
    "\n",
    "    individual_model_accuracy = []\n",
    "    for result_df in results_files:\n",
    "        individual_model_accuracy.append( float(result_df['valAcc'].tail(1).values[0]))\n",
    "    \n",
    "    \n",
    "    output['max_individual_accuracy'] = max(individual_model_accuracy)\n",
    "    output['min_individual_accuracy'] = min(individual_model_accuracy)\n",
    "    output['mean_individual_accuracy'] = mean(individual_model_accuracy)\n",
    "    output['stdev_individual_accuracy'] = stdev(individual_model_accuracy)\n",
    "    output['ensemble_max_improvement'] = output['ensemble_accuracy'] - output['max_individual_accuracy']\n",
    "    output['ensemble_mean_improvement'] = output['ensemble_accuracy'] - output['mean_individual_accuracy']\n",
    "    \n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here are the results from the 10 5epoch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble_accuracy': 0.5994,\n",
       " 'max_individual_accuracy': 0.5912,\n",
       " 'min_individual_accuracy': 0.58,\n",
       " 'mean_individual_accuracy': 0.58567,\n",
       " 'stdev_individual_accuracy': 0.003153851261200784,\n",
       " 'ensemble_max_improvement': 0.008200000000000096,\n",
       " 'ensemble_mean_improvement': 0.01373000000000002}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_prefix = 'seed'\n",
    "num_of_models = 10\n",
    "path = 'Z:/VQA-Capstone-Project/'\n",
    "\n",
    "r = ensemble_results(experiment_prefix, num_of_models, path)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here are the results from the 10 15epoch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ensemble_accuracy': 0.63,\n",
       " 'max_individual_accuracy': 0.6221,\n",
       " 'min_individual_accuracy': 0.5905,\n",
       " 'mean_individual_accuracy': 0.60533,\n",
       " 'stdev_individual_accuracy': 0.013532926923290133,\n",
       " 'ensemble_max_improvement': 0.007900000000000018,\n",
       " 'ensemble_mean_improvement': 0.02466999999999997}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_prefix = '15epoch_seed'\n",
    "num_of_models = 10\n",
    "path = 'Z:/VQA-Capstone-Project/'\n",
    "\n",
    "r = ensemble_results(experiment_prefix, num_of_models, path)\n",
    "r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
