{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for inspecting files\n",
    "import json\n",
    "import pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "word_embed_size = 50\n",
    "max_objects = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 3.9 seconds\n",
      "400000\n"
     ]
    }
   ],
   "source": [
    "embed_dict = {}\n",
    "start_time = time.time()\n",
    "with open('./data/glove.6B.'+str(word_embed_size)+'d.txt') as f:\n",
    "    for line in f:\n",
    "        wordsAndVectors = line.strip().split(' ')\n",
    "        word = wordsAndVectors[0]\n",
    "        vector = wordsAndVectors[1:]\n",
    "        vector = list(map(float, vector))\n",
    "        embed_dict[word] = vector\n",
    "\n",
    "print('Time elapsed:', np.round(time.time() - start_time,1), \"seconds\")\n",
    "\n",
    "print(len(embed_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that breaks text into words and uses the embedding dictionary returning the average for each word\n",
    "def encode_text(text):\n",
    "    word_list = list(text.split())\n",
    "    if len(word_list) == 1:\n",
    "        if word_list[0] in embed_dict:\n",
    "\n",
    "            embedding = np.array(embed_dict[word_list[0]])\n",
    "        else:\n",
    "\n",
    "            embedding = np.zeros(word_embed_size)\n",
    "    else:\n",
    "        embed_list = np.zeros((len(word_list), word_embed_size))\n",
    "\n",
    "        for i in range(len(word_list)):\n",
    "            if word_list[i] in embed_dict:\n",
    "                embed_list[i] = embed_dict[word_list[i]]\n",
    "      \n",
    "        embedding = np.mean(embed_list, axis=0)\n",
    "    return embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def parse_graph (data_sg, num_images_feed, index_start=0, report_interval=5000):\n",
    "\n",
    "    # Initialise data files\n",
    "    bboxes_matrix = np.zeros((num_images_feed, max_objects, 4))\n",
    "    features_matrix = np.zeros((num_images_feed, max_objects, 4*word_embed_size))\n",
    "    image_info_dict = {}\n",
    "    image_count=0\n",
    "    #index_to_image = {} #Z# inspection code\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for image_id in data_sg:\n",
    "\n",
    "        if image_count % report_interval == 0:\n",
    "            print('Progress:', str(np.round(100*(image_count / num_images_feed),0))\n",
    "                  +'%, Time:', np.round(time.time() - start_time,1), \"seconds\")\n",
    "\n",
    "        object_name_dict = {}\n",
    "\n",
    "        # First pass is to go through the object list and build dictionary of objects so relations can recognise\n",
    "        for object_id in data_sg[image_id]['objects']:\n",
    "            object_name_dict[object_id] = data_sg[image_id]['objects'][object_id]['name']\n",
    "\n",
    "        # Second pass is to build the embeddings         \n",
    "        object_count = 0\n",
    "\n",
    "        #obj_list = [] #Z\n",
    "        for object_id in data_sg[image_id]['objects']:\n",
    "\n",
    "            # Get bounding box details and store\n",
    "            x = data_sg[image_id]['objects'][object_id]['x']\n",
    "            y = data_sg[image_id]['objects'][object_id]['y']\n",
    "            h = data_sg[image_id]['objects'][object_id]['h']\n",
    "            w = data_sg[image_id]['objects'][object_id]['w']\n",
    "            bboxes_matrix[image_count, object_count] = [x,y,h,w]\n",
    "\n",
    "            obj_name = data_sg[image_id]['objects'][object_id]['name']\n",
    "            #obj_list.append(obj_name) #Z\n",
    "            object_name_encode = encode_text(obj_name)\n",
    "            objects_list = object_name_encode\n",
    "\n",
    "            # Get mean attribute encodings for each object       \n",
    "            n_attribs = len(data_sg[image_id]['objects'][object_id]['attributes'])        \n",
    "            attribs_list = np.zeros(word_embed_size)\n",
    "\n",
    "            if n_attribs >= 1:\n",
    "                if n_attribs == 1:\n",
    "                    for attribute in data_sg[image_id]['objects'][object_id]['attributes']:\n",
    "                        attribs_list = encode_text(attribute)\n",
    "                elif n_attribs > 1:\n",
    "                    attribs_sublists = np.zeros((n_attribs, word_embed_size))\n",
    "                    attrib_count = 0\n",
    "                    for attribute in data_sg[image_id]['objects'][object_id]['attributes']:\n",
    "\n",
    "                        attribs_sublists[attrib_count] = encode_text(attribute)\n",
    "                        attrib_count += 1\n",
    "                    attribs_list = np.mean(attribs_sublists, axis=0)       \n",
    "\n",
    "            # Get mean relation encodings for each object       \n",
    "            n_relations = len(data_sg[image_id]['objects'][object_id]['relations'])     \n",
    "            relation_object_list = np.zeros(word_embed_size)\n",
    "            relationship_list = np.zeros(word_embed_size)\n",
    "\n",
    "            if n_relations >= 1:\n",
    "                if n_relations == 1:\n",
    "\n",
    "                    for relation in data_sg[image_id]['objects'][object_id]['relations']:\n",
    "                        rel_object_id = relation['object']\n",
    "                        if rel_object_id in object_name_dict:    \n",
    "                            rel_object_name = object_name_dict[rel_object_id]\n",
    "                            relations_object_list = encode_text(rel_object_name)\n",
    "                        relationship_list = encode_text(relation['name'])\n",
    "\n",
    "                elif n_relations > 1:    \n",
    "                    relations_objects_sublists = np.zeros((n_relations, word_embed_size))\n",
    "                    relationships_sublists = np.zeros((n_relations, word_embed_size))\n",
    "                    relations_count = 0  \n",
    "                    for relation in data_sg[image_id]['objects'][object_id]['relations']:\n",
    "                        rel_object_id = relation['object']\n",
    "                        if rel_object_id in object_name_dict:    \n",
    "                            rel_object_name = object_name_dict[rel_object_id]\n",
    "                            relations_objects_sublists[relations_count] = encode_text(rel_object_name)\n",
    "                        relationships_sublists[relations_count] = encode_text(relation['name'])\n",
    "                        relations_count += 1\n",
    "                    relation_object_list = np.mean(relations_objects_sublists, axis=0)\n",
    "                    relationship_list = np.mean(relationships_sublists, axis=0)\n",
    "\n",
    "            features_list = np.concatenate([objects_list, attribs_list, relation_object_list, relationship_list])\n",
    "            features_matrix[image_count, object_count] = features_list\n",
    "\n",
    "            object_count += 1\n",
    "            if object_count >= 100:\n",
    "                break\n",
    "\n",
    "        # Create image summary info\n",
    "        image_info_dict[str(image_id)] = {'width': data_sg[image_id]['width'], 'objectsNum': object_count,\n",
    "                                          'height': data_sg[image_id]['height'], 'index': image_count+index_start}\n",
    "\n",
    "        #index_to_image[image_count]=[image_id, obj_list] #Z inspection code\n",
    "\n",
    "        image_count +=1\n",
    "        if image_count >= num_images_feed:\n",
    "            break\n",
    "\n",
    "    print('\\nComplete. Time elapsed:', np.round(time.time() - start_time,0), \"seconds\")\n",
    "    return bboxes_matrix, features_matrix, image_info_dict, image_count\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/sceneGraphs/train_sceneGraphs.json') as f:\n",
    "    data_sg = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.0%, Time: 0.0 seconds\n",
      "Progress: 7.0%, Time: 6.7 seconds\n",
      "Progress: 13.0%, Time: 13.5 seconds\n",
      "Progress: 20.0%, Time: 20.4 seconds\n",
      "Progress: 27.0%, Time: 27.4 seconds\n",
      "Progress: 33.0%, Time: 34.3 seconds\n",
      "Progress: 40.0%, Time: 41.3 seconds\n",
      "Progress: 47.0%, Time: 48.3 seconds\n",
      "Progress: 53.0%, Time: 55.1 seconds\n",
      "Progress: 60.0%, Time: 62.2 seconds\n",
      "Progress: 67.0%, Time: 69.0 seconds\n",
      "Progress: 73.0%, Time: 75.9 seconds\n",
      "Progress: 80.0%, Time: 82.7 seconds\n",
      "Progress: 87.0%, Time: 89.6 seconds\n",
      "Progress: 93.0%, Time: 96.3 seconds\n",
      "\n",
      "Complete. Time elapsed: 103.0 seconds\n"
     ]
    }
   ],
   "source": [
    "bboxes_train, features_train, image_info_train, n_train = parse_graph (data_sg, len(data_sg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxes_train.shape: (74942, 100, 4)\n",
      "features_train.shape: (74942, 100, 200)\n",
      "len(image_info_train): 74942\n",
      "n_train: 74942\n"
     ]
    }
   ],
   "source": [
    "print('bboxes_train.shape:', bboxes_train.shape)\n",
    "print('features_train.shape:', features_train.shape)\n",
    "print('len(image_info_train):', len(image_info_train))\n",
    "print('n_train:', n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 0.0%, Time: 0.0 seconds\n",
      "Progress: 47.0%, Time: 6.7 seconds\n",
      "Progress: 93.0%, Time: 13.6 seconds\n",
      "\n",
      "Complete. Time elapsed: 15.0 seconds\n"
     ]
    }
   ],
   "source": [
    "with open('./data/sceneGraphs/val_sceneGraphs.json') as f:\n",
    "    data_sg = json.load(f)\n",
    "bboxes_val, features_val, image_info_val, n_val = parse_graph (data_sg, len(data_sg), index_start = n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bboxes_val.shape: (10696, 100, 4)\n",
      "features_tval.shape: (10696, 100, 200)\n",
      "len(image_info_val): 10696\n",
      "n_val: 10696\n"
     ]
    }
   ],
   "source": [
    "print('bboxes_val.shape:', bboxes_val.shape)\n",
    "print('features_tval.shape:', features_val.shape)\n",
    "print('len(image_info_val):', len(image_info_val))\n",
    "print('n_val:', n_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_matrix = np.concatenate((bboxes_train, bboxes_val))\n",
    "features_matrix = np.concatenate((features_train, features_val))\n",
    "image_info_dict = {**image_info_train, **image_info_val}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bboxes_train = bboxes_val = features_train = features_val = image_info_train = image_info_val = data_sg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding boxes: shape = (85638, 100, 4)\n",
      "Image 0:\n",
      " [[248.  55.  34.  64.]\n",
      " [245.  92.  16.  26.]\n",
      " [268.  32.  50.  49.]\n",
      " [  0.   0. 374. 499.]\n",
      " [402.  55.  95.  15.]\n",
      " [ 68. 123.  27.  24.]\n",
      " [ 57. 162.  57.  93.]\n",
      " [ 90. 147.  16.  24.]\n",
      " [  0.   0. 374. 396.]\n",
      " [178. 184.  99. 115.]]\n",
      "\n",
      "Image 1:\n",
      " [[134.   0.  85.  56.]\n",
      " [143.  15.  16.  29.]\n",
      " [249.  13.  33.  32.]\n",
      " [304.  11.  65.  26.]\n",
      " [261.  54.  21.  29.]\n",
      " [382.   0. 145.  13.]\n",
      " [281.   0. 116.  23.]\n",
      " [460.   1. 104.  23.]\n",
      " [395.  40.  33.  21.]\n",
      " [213.  53.  30.  29.]]\n",
      "\n",
      "Image 2:\n",
      " [[215. 227. 106. 147.]\n",
      " [ 12. 260.  43.  95.]\n",
      " [384. 186. 147. 104.]\n",
      " [108.  89. 116.  54.]\n",
      " [234. 110.  70.  40.]\n",
      " [  0. 242.  91. 109.]\n",
      " [  0. 201.  35.  52.]\n",
      " [108. 173.  31.  35.]\n",
      " [246. 109.  13.  15.]\n",
      " [ 44. 128.  98. 162.]]\n"
     ]
    }
   ],
   "source": [
    "print('Bounding boxes: shape =', bboxes_matrix.shape)\n",
    "print('Image 0:\\n', bboxes_matrix[0][0:10])\n",
    "print('\\nImage 1:\\n', bboxes_matrix[1][0:10])\n",
    "print('\\nImage 2:\\n', bboxes_matrix[2][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85638\n",
      "{\n",
      "    \"height\": 281,\n",
      "    \"index\": 1,\n",
      "    \"objectsNum\": 29,\n",
      "    \"width\": 500\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(len(image_info_dict))\n",
    "print(json.dumps(image_info_dict['2373554'], sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: shape = (85638, 100, 200)\n",
      "\n",
      "Image 0 (name encoding):\n",
      " [[-0.255 -0.752 -0.867  1.12   0.129  1.012 -0.572 -0.362  0.443 -0.122]\n",
      " [ 0.195  0.802  0.366  0.617 -0.028 -0.018 -1.003 -0.117  0.615 -0.642]\n",
      " [-0.241 -1.011 -0.825  0.313  0.564  0.434 -0.625 -0.936  0.145  0.366]\n",
      " [-0.303  1.244 -1.087  0.247  0.093 -0.772 -1.22  -0.17   0.564 -0.697]\n",
      " [-0.384  0.191 -0.505  0.106  0.138  0.135 -0.705 -0.468 -0.062 -1.069]]\n",
      "\n",
      "Image 0 (attributes encoding):\n",
      " [[ 0.481  0.489 -0.239 -0.071  0.535  0.471 -0.685 -0.472  0.17  -0.573]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.481  0.489 -0.239 -0.071  0.535  0.471 -0.685 -0.472  0.17  -0.573]\n",
      " [ 0.667  0.064 -1.63   0.103  0.911  0.173 -0.099  0.092  0.101  1.165]\n",
      " [-0.464  0.333 -0.211 -0.129  0.763  0.812 -0.644 -1.022 -0.27  -0.704]]\n",
      "\n",
      "Image 0 (relation object encoding):\n",
      " [[ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [-0.367 -0.532 -1.209  0.694  0.283  0.586 -0.536 -0.493  0.322 -0.407]]\n",
      "\n",
      "Image 0 (relationship encoding):\n",
      " [[ 0.569  0.186 -0.043 -0.08   0.477  0.236 -0.46   0.076 -0.23  -0.458]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.569  0.186 -0.043 -0.08   0.477  0.236 -0.46   0.076 -0.23  -0.458]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [ 0.372  0.172 -0.158 -0.083  0.533  0.318 -0.275 -0.087 -0.095 -0.244]]\n"
     ]
    }
   ],
   "source": [
    "print('Features: shape =', features_matrix.shape)\n",
    "print('\\nImage 0 (name encoding):\\n', np.round(\n",
    "    features_matrix[0, 0:5, 0:10],3))\n",
    "print('\\nImage 0 (attributes encoding):\\n', np.round(\n",
    "    features_matrix[0, 0:5, word_embed_size*1:word_embed_size*1+10],3))\n",
    "print('\\nImage 0 (relation object encoding):\\n', np.round(\n",
    "    features_matrix[0, 0:5, word_embed_size*2:word_embed_size*2+10],3))\n",
    "print('\\nImage 0 (relationship encoding):\\n', np.round(\n",
    "    features_matrix[0, 0:5, word_embed_size*3:word_embed_size*3+10],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 (name encoding):\n",
      " [[ 0.622  1.199 -0.014  0.201  0.694  0.121 -0.904 -1.402  0.434 -0.485]\n",
      " [ 0.888  1.072 -0.09  -0.084  1.154  0.648  0.076  0.215 -0.259 -0.953]\n",
      " [ 0.888  1.072 -0.09  -0.084  1.154  0.648  0.076  0.215 -0.259 -0.953]\n",
      " [ 0.888  1.072 -0.09  -0.084  1.154  0.648  0.076  0.215 -0.259 -0.953]\n",
      " [ 0.888  1.072 -0.09  -0.084  1.154  0.648  0.076  0.215 -0.259 -0.953]]\n",
      "\n",
      "Image 1 (attributes encoding):\n",
      " [[ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [-0.577  0.87  -0.491 -0.108  0.654  0.325 -1.326 -1.011 -0.207 -0.799]\n",
      " [-0.577  0.87  -0.491 -0.108  0.654  0.325 -1.326 -1.011 -0.207 -0.799]\n",
      " [-0.577  0.87  -0.491 -0.108  0.654  0.325 -1.326 -1.011 -0.207 -0.799]\n",
      " [-0.577  0.87  -0.491 -0.108  0.654  0.325 -1.326 -1.011 -0.207 -0.799]]\n",
      "\n",
      "Image 1 (relation object encoding):\n",
      " [[ 0.546  0.89  -0.066  0.08   0.823  0.295 -0.481 -0.489  0.    -0.713]\n",
      " [ 0.644  1.043  0.032  0.17   0.726  0.214 -0.675 -0.857  0.178 -0.668]\n",
      " [ 0.685  1.048  0.011  0.128  0.797  0.286 -0.55  -0.679  0.105 -0.715]\n",
      " [ 0.521  0.963 -0.165  0.032  0.899  0.313 -0.486 -0.645  0.081 -0.616]\n",
      " [ 0.46   0.887 -0.11   0.092  0.79   0.229 -0.603 -0.718  0.096 -0.613]]\n",
      "\n",
      "Image 1 (relationship encoding):\n",
      " [[ 0.49   0.18  -0.089 -0.081  0.5    0.269 -0.386  0.011 -0.176 -0.373]\n",
      " [ 0.49   0.18  -0.089 -0.081  0.5    0.269 -0.386  0.011 -0.176 -0.373]\n",
      " [ 0.47   0.179 -0.1   -0.081  0.505  0.277 -0.368 -0.006 -0.162 -0.351]\n",
      " [ 0.428  0.176 -0.125 -0.082  0.517  0.294 -0.328 -0.041 -0.134 -0.305]\n",
      " [ 0.484  0.18  -0.092 -0.081  0.501  0.271 -0.381  0.006 -0.172 -0.367]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nImage 1 (name encoding):\\n', np.round(\n",
    "    features_matrix[1, 0:5, 0:10],3))\n",
    "print('\\nImage 1 (attributes encoding):\\n', np.round(\n",
    "    features_matrix[1, 0:5, word_embed_size*1:word_embed_size*1+10],3))\n",
    "print('\\nImage 1 (relation object encoding):\\n', np.round(\n",
    "    features_matrix[1, 0:5, word_embed_size*2:word_embed_size*2+10],3))\n",
    "print('\\nImage 1 (relationship encoding):\\n', np.round(\n",
    "    features_matrix[1, 0:5, word_embed_size*3:word_embed_size*3+10],3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 (name encoding):\n",
      " [[-1.000e-03 -3.010e-01 -1.880e-01 -5.450e-01 -6.460e-01  6.040e-01\n",
      "  -1.050e-01 -3.010e-01 -2.430e-01 -6.140e-01]\n",
      " [ 5.350e-01  5.760e-01 -5.400e-02 -2.080e-01 -7.880e-01 -1.760e-01\n",
      "  -2.130e-01 -1.440e-01  1.034e+00 -7.900e-02]\n",
      " [ 2.250e-01  3.840e-01 -5.010e-01  1.670e-01  2.530e-01  6.700e-02\n",
      "  -4.540e-01  7.200e-02  2.800e-01 -1.385e+00]\n",
      " [-4.170e-01  4.650e-01  1.380e-01 -1.930e-01  1.011e+00  1.500e-01\n",
      "  -2.000e-02  3.730e-01 -3.730e-01 -8.900e-01]\n",
      " [-9.400e-02  4.300e-01 -1.720e-01 -4.550e-01  1.645e+00  4.030e-01\n",
      "  -3.730e-01  2.510e-01 -1.060e-01  1.080e-01]]\n",
      "\n",
      "Image 2 (attributes encoding):\n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "\n",
      "Image 2 (relation object encoding):\n",
      " [[ 0.467  0.254 -0.004 -0.046 -0.518 -0.07  -0.408  0.102  0.407 -0.654]\n",
      " [-0.161 -0.044 -0.497 -0.215 -0.675  0.283 -0.236 -0.291  0.041 -0.641]\n",
      " [ 0.     0.     0.     0.     0.     0.     0.     0.     0.     0.   ]\n",
      " [-0.328  0.298  0.16  -0.16   0.214  0.308 -0.559 -0.422  0.748 -0.473]\n",
      " [-0.393  0.305  0.222 -0.108  0.087  0.258 -0.489 -0.397  0.694 -0.672]]\n",
      "\n",
      "Image 2 (relationship encoding):\n",
      " [[ 0.438  0.176 -0.12  -0.082  0.515  0.29  -0.337 -0.033 -0.14  -0.315]\n",
      " [ 0.569  0.186 -0.043 -0.08   0.477  0.236 -0.46   0.076 -0.23  -0.458]\n",
      " [ 0.372  0.172 -0.158 -0.083  0.533  0.318 -0.275 -0.087 -0.095 -0.244]\n",
      " [ 0.26   0.146 -0.113 -0.141  0.291  0.364 -0.558  0.041 -0.111 -0.526]\n",
      " [-0.153  0.185 -0.301 -0.271  0.424  0.359 -0.519 -0.198 -0.081 -0.514]]\n"
     ]
    }
   ],
   "source": [
    "print('\\nImage 2 (name encoding):\\n', np.round(\n",
    "    features_matrix[2, 0:5, 0:10],3))\n",
    "print('\\nImage 2 (attributes encoding):\\n', np.round(\n",
    "    features_matrix[2, 0:5, word_embed_size*1:word_embed_size*1+10],3))\n",
    "print('\\nImage 2 (relation object encoding):\\n', np.round(\n",
    "    features_matrix[2, 0:5, word_embed_size*2:word_embed_size*2+10],3))\n",
    "print('\\nImage 2 (relationship encoding):\\n', np.round(\n",
    "    features_matrix[2, 0:5, word_embed_size*3:word_embed_size*3+10],3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking question and answer code for images not in scene graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/balanced_train_data.json') as f:\n",
    "    data_bal_train = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: dict_keys(['questions'])\n"
     ]
    }
   ],
   "source": [
    "print(\"Keys: %s\" % data_bal_train.keys())\n",
    "bal_tr_key = list(data_bal_train.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132062\n"
     ]
    }
   ],
   "source": [
    "print(len(data_bal_train['questions']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number not in dict = 0\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "i_max = 999000\n",
    "data_bal_train_sg = {}\n",
    "n_false = 0\n",
    "\n",
    "for qa_item in data_bal_train['questions']:\n",
    "    #print(qa_item['imageId'], qa_item)\n",
    "    if qa_item['imageId'] in image_info_dict:\n",
    "        #print(True)\n",
    "        n_false = n_false\n",
    "    else:\n",
    "        #print(False)\n",
    "        n_false += 1\n",
    "    i += 1\n",
    "    if i > i_max:\n",
    "        break\n",
    "print(\"Number not in dict =\", n_false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Savings data to JSON and H5 file formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write JSON File\n",
    "with open('./data/gqa_objects_sg_merged_info.json', 'w') as outfile:\n",
    "    json.dump(image_info_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write H5PY File\n",
    "export_file = h5py.File('./data/gqa_objects_sg.h5', 'w')\n",
    "export_file.create_dataset('bboxes', data=bboxes_matrix)\n",
    "export_file.create_dataset('features', data=features_matrix)\n",
    "export_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing file saves by uploading and reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load merged file dictionary\n",
    "with open('./data/gqa_objects_sg_merged_info.json') as f:\n",
    "    data_info_dict = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85638\n"
     ]
    }
   ],
   "source": [
    "print(len(data_info_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2386621 {'width': 500, 'objectsNum': 16, 'height': 375, 'index': 0}\n",
      "2373554 {'width': 500, 'objectsNum': 29, 'height': 281, 'index': 1}\n",
      "2370799 {'width': 500, 'objectsNum': 16, 'height': 333, 'index': 2}\n",
      "2370791 {'width': 500, 'objectsNum': 16, 'height': 333, 'index': 3}\n",
      "\n",
      "2374606 {'width': 500, 'objectsNum': 21, 'height': 375, 'index': 85633}\n",
      "2360947 {'width': 500, 'objectsNum': 15, 'height': 375, 'index': 85634}\n",
      "2360946 {'width': 375, 'objectsNum': 5, 'height': 500, 'index': 85635}\n",
      "2379678 {'width': 500, 'objectsNum': 25, 'height': 334, 'index': 85636}\n",
      "2379672 {'width': 500, 'objectsNum': 9, 'height': 333, 'index': 85637}\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "j = len(data_info_dict)\n",
    "\n",
    "for item in data_info_dict:\n",
    "    \n",
    "    i += 1\n",
    "    if i < 5:\n",
    "        print(item, data_info_dict[str(item)])\n",
    "    if i == 5:\n",
    "        print()\n",
    "    if (j-i) < 5:\n",
    "        print(item, data_info_dict[str(item)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open objects file and inspect\n",
    "file_objects = './data/gqa_objects_sg.h5'\n",
    "data_obs = h5py.File(file_objects, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['bboxes', 'features']>\n"
     ]
    }
   ],
   "source": [
    "# List all groups\n",
    "print(\"Keys: %s\" % data_obs.keys())\n",
    "obs_key = list(data_obs.keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 objects (bounding boxes): shape = (85638, 100, 4) \n",
      "\n",
      " [[134.   0.  85.  56.]\n",
      " [143.  15.  16.  29.]\n",
      " [249.  13.  33.  32.]\n",
      " [304.  11.  65.  26.]\n",
      " [261.  54.  21.  29.]\n",
      " [382.   0. 145.  13.]\n",
      " [281.   0. 116.  23.]\n",
      " [460.   1. 104.  23.]\n",
      " [395.  40.  33.  21.]\n",
      " [213.  53.  30.  29.]]\n",
      "\n",
      "Image 85637 objects (bounding boxes): shape = (85638, 100, 4) \n",
      "\n",
      " [[ 73.   2.  98. 267.]\n",
      " [158. 164.  56.  61.]\n",
      " [133. 100.   9.  12.]\n",
      " [ 58.  97. 145. 116.]\n",
      " [158. 163.  78.  90.]\n",
      " [ 32. 220.  50. 188.]\n",
      " [292.   0. 332. 207.]\n",
      " [ 97.  97.  45.  47.]\n",
      " [ 26.  88. 244. 198.]\n",
      " [  0.   0.   0.   0.]]\n"
     ]
    }
   ],
   "source": [
    "print('Image 1 objects (bounding boxes): shape =', \n",
    "      data_obs['bboxes'].shape, '\\n\\n', data_obs['bboxes'][1][0:10])\n",
    "print('\\nImage',j-1,'objects (bounding boxes): shape =', \n",
    "      data_obs['bboxes'].shape, '\\n\\n', data_obs['bboxes'][j-1][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 1 objects (features): shape = (85638, 100, 200) \n",
      "\n",
      " [[ 0.62  1.2  -0.01  0.2   0.69  0.12 -0.9  -1.4   0.43 -0.49]\n",
      " [ 0.89  1.07 -0.09 -0.08  1.15  0.65  0.08  0.22 -0.26 -0.95]\n",
      " [ 0.89  1.07 -0.09 -0.08  1.15  0.65  0.08  0.22 -0.26 -0.95]\n",
      " [ 0.89  1.07 -0.09 -0.08  1.15  0.65  0.08  0.22 -0.26 -0.95]\n",
      " [ 0.89  1.07 -0.09 -0.08  1.15  0.65  0.08  0.22 -0.26 -0.95]]\n",
      "\n",
      "Image 85637 objects (features): shape = (85638, 100, 200) \n",
      "\n",
      " [[ 0.26  0.32  0.74 -0.37  0.66 -0.49 -0.56 -0.24 -0.45 -0.13]\n",
      " [-0.46  0.52 -1.   -0.45  0.54  1.37 -0.07 -1.2   0.07  0.45]\n",
      " [ 0.07 -0.03 -0.2  -0.27  0.18  0.78  0.88  0.37  0.53  0.08]\n",
      " [ 0.45 -0.5  -0.54 -0.02  0.22  0.55 -0.67 -0.69  0.63 -0.2 ]\n",
      " [ 0.3   0.41 -0.38 -1.21  1.05  1.58 -0.15 -0.28  1.01  0.09]]\n"
     ]
    }
   ],
   "source": [
    "# Get shape and visualise features\n",
    "print('Image 1 objects (features): shape =', \n",
    "      data_obs['features'].shape, '\\n\\n', np.round(data_obs['features'][1, 0:5, 0:10],2))\n",
    "print('\\nImage',j-1,'objects (features): shape =', \n",
    "      data_obs['features'].shape, '\\n\\n', np.round(data_obs['features'][j-1, 0:5, 0:10],2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
